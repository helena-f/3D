<!DOCTYPE html>
<html>
<head>
  <title>3D on a Webpage</title>
  <meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
  <link href="https://fonts.googleapis.com/css2?family=Epilogue&display=swap" rel="stylesheet">
  <link rel="stylesheet" type="text/css" href="base.css">

</head>
<body>
  <h1>Frameworks, Libraries, and Models for Image Recognition</h1>
  <h4 class="note">*Included are small snippets of our thousands of lines of code</h4>

  <p>Each library has its strengths and weaknesses. Vuforia was accurate, but only for stationary images. TensorFlow was inaccurate, but fast. OpenCV was much more accurate and still processed quickly.</p>
  <h2>1. Vuforia</h2>
    <p>The Vuforia Engine detects and tracks an image by comparing extracted natural features from our live feed against our compiled image database of an element.</p>
    <h2>2. TensorFlow</h2>
    <img src="resources/tf.png" alt="" width="300px">
    <p>Given the live camera stream, we used TF to create an object detection model that can identify which of a known set of objects might be present and provide information about their positions within the image.</p>
   
    <h2>3. OpenCV</h2>
    <p>OpenCV is a huge open-source library for computer vision, machine learning, and image processing. 
        We take live footage from the robot controller phone and feed it through a pipeline. 
        Then, using a comparative image overlay, the algorithm calculates if and where certain elements are on the field. 
        It compares the live images with custom template images to determine confidence rate based on shape, color, and size.
    Here is an example of our implementation. </p>
        <img src="resources/cv.png" alt="" width="400px">

</body>
</html>